§u§
```
Large Language Models are sophisticated mathematical functions. As an input, they take a list of tokens and try to predict the next token. A token can be a character, a number, a word or a part of a word. Any text can be represented as such a list of tokens. By chaining this process together, it is possible to not only predict a single token but also an entire text. 
```
Shorten this for a powerpoint slide.
§a§
**"Large Language Models (LLMs): How They Work"**

- **Input:** A sequence of *tokens* (words, subwords, or characters).
- **Core Task:** Predict the *next token* using statistical patterns.
- **Output:** Generate coherent text by repeating this process.

*Key Idea:* **Text → Tokens → Probabilistic Prediction → Generated Text**
